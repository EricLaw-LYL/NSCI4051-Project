@misc{game_date,
    author = {The Learning Agency Lab},
    title = {Predict Student Performance from Game Play},
    year = {2023},
    howpublished= {\url{https://www.kaggle.com/competitions/predict-student-performance-from-game-play/overview}}, 
    note = "Accessed: 2023-03-18"
} 

@misc{jo_wilder,
    author = {PBS Wisconsin Education},
    title = {Jo Wilder and the Capitol Case},
    year = {2021},
    howpublished= {\url{https://pbswisconsineducation.org/jowilder/about/}}, 
    note = "Accessed: 2023-03-18"
}

@misc{simple_xgb,
    author = {MACHENGYUAN},
    title = {Simple XGB model},
    year = {2023},
    howpublished= {\url{https://www.kaggle.com/code/machengyuan/simple-xgb-model/notebook}}, 
    note = "Accessed: 2023-03-25"
}

@misc{detailed_eda,
    author = {Paul Bacher},
    title = {Predict Student Performance from Game Play},
    year = {2023},
    howpublished= {\url{https://www.kaggle.com/code/paulbacher/detailed-eda-student-perf-from-game-play}}, 
    note = "Accessed: 2023-03-23"
}

@misc{polars,
    author = {Ritchie Vink},
    title = {Polars: Blazingly fast DataFrames},
    year = {2017},
    howpublished= {\url{https://www.pola.rs/}}, 
    note = "Accessed: 2023-03-25"
}

@misc{group_k_fold,
    author = {scikit-learn developers},
    title = {Visualizing cross-validation behavior in scikit-learn},
    year = {2022},
    howpublished= {\url{https://scikit-learn.org/stable/auto_examples/model_selection/plot_cv_indices.html#sphx-glr-auto-examples-model-selection-plot-cv-indices-py}}, 
    note = "Accessed: 2023-03-27"
}

@article{random_forest,
    author = {Padovese, Bruno and Padovese, L.R.},
    year = {2019},
    month = {12},
    pages = {5},
    title = {A Machine Learning Approach to the Recognition of Brazilian Atlantic Forest Parrot Species},
    note = {10.1101/2019.12.24.888180}
}

@inproceedings{xgb,
    author = {Chen, Tianqi and Guestrin, Carlos},
    title = {{XGBoost}: A Scalable Tree Boosting System},
    booktitle = {Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
    series = {KDD '16},
    year = {2016},
    isbn = {978-1-4503-4232-2},
    location = {San Francisco, California, USA},
    pages = {785--794},
    numpages = {10},
    url = {http://doi.acm.org/10.1145/2939672.2939785},
    note = {10.1145/2939672.2939785},
    acmid = {2939785},
    publisher = {ACM},
    address = {New York, NY, USA},
    keywords = {large-scale machine learning},
}

@Inbook{Cutler2012,
    author="Cutler, Adele
    and Cutler, D. Richard
    and Stevens, John R.",
    editor="Zhang, Cha
    and Ma, Yunqian",
    title="Random Forests",
    bookTitle="Ensemble Machine Learning: Methods and Applications",
    year="2012",
    publisher="Springer New York",
    address="New York, NY",
    pages="157--175",
    abstract="Random Forests were introduced by Leo Breiman [6] who was inspired by earlier work by Amit and Geman [2]. Although not obvious from the description in [6], Random Forests are an extension of Breiman's bagging idea [5] and were developed as a competitor to boosting. Random Forests can be used for either a categorical response variable, referred to in [6] as ``classification,'' or a continuous response, referred to as ``regression.'' Similarly, the predictor variables can be either categorical or continuous.",
    isbn="978-1-4419-9326-7",
    note ="10.1007/978-1-4419-9326-7\_5",
    url="https://doi.org/10.1007/978-1-4419-9326-7_5"
}

@article{ZOU20162,
    author = {Quan Zou and Sifa Xie and Ziyu Lin and Meihong Wu and Ying Ju},
    title = {Finding the Best Classification Threshold in Imbalanced Classification},
    journal = {Big Data Research},
    volume = {5},
    pages = {2-8},
    year = {2016},
    note = {10.1016/j.bdr.2015.12.001},
    url = {https://www.sciencedirect.com/science/article/pii/S2214579615000611},
    keywords = {Receiver Operating Characteristic (ROC), Protein remote homology detection, Imbalance data, F-score},
    abstract = {Classification with imbalanced class distributions is a major problem in machine learning. Researchers have given considerable attention to the applications in many real-world scenarios. Although several works have utilized the area under the receiver operating characteristic (ROC) curve to select potentially optimal classifiers in imbalanced classifications, limited studies have been devoted to finding the classification threshold for testing or unknown datasets. In general, the classification threshold is simply set to 0.5, which is usually unsuitable for an imbalanced classification. In this study, we analyze the drawbacks of using ROC as the sole measure of imbalance in data classification problems. In addition, a novel framework for finding the best classification threshold is proposed. Experiments with SCOP v.1.53 data reveal that, with the default threshold set to 0.5, our proposed framework demonstrated a 20.63\% improvement in terms of F-score compared with that of more commonly used methods. The findings suggest that the proposed framework is both effective and efficient. A web server and software tools are available via http://datamining.xmu.edu.cn/prht/ or http://prht.sinaapp.com/.}
}

@ARTICLE{7870510,
  author={Zhao, Bendong and Lu, Huanzhang and Chen, Shangfeng and Liu, Junliang and Wu, Dongya},
  journal={Journal of Systems Engineering and Electronics}, 
  title={Convolutional neural networks for time series classification}, 
  year={2017},
  volume={28},
  number={1},
  pages={162-169},
  note={10.21629/JSEE.2017.01.18}
}